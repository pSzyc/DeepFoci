{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024b29c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tifffile import imread\n",
    "from scipy.ndimage import zoom\n",
    "from skimage.segmentation import watershed\n",
    "from scipy.ndimage import label as ndi_label\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import h_maxima\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../utils\")\n",
    "\n",
    "from utils.predict_by_parts import predict_by_parts\n",
    "from norm_percentile_nocrop import norm_percentile_nocrop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3608c57e",
   "metadata": {},
   "source": [
    "# Load the timage and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d817f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = torch.load(\"detection_model.pt\", map_location=torch.device(\"cpu\"))\n",
    "folder_name_to_evaluate = \"../../data_zenodo/NHDF/NHDF_8h PI/IR 0,5Gy_8h PI/0001\"\n",
    "\n",
    "detection_channel = 2  # red 0, green 1, red and green 2\n",
    "resized_img_size = [505, 681, 48]  # image is resized to this size\n",
    "normalization_percentile = 0.0001  # image is normalized into this percentile range\n",
    "crop_size = [96, 96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04db45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filename = folder_name_to_evaluate + \"/data_53BP1.tif\"\n",
    "img = []\n",
    "img.append(imread(img_filename))  # red\n",
    "img.append(imread(img_filename.replace(\"53BP1\", \"gH2AX\")))  # green\n",
    "img.append(imread(img_filename.replace(\"53BP1\", \"DAPI\")))  # DAPI\n",
    "\n",
    "img = np.stack(img, axis=3)\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "img_orig_size = img.shape[:3]\n",
    "factor = np.array(resized_img_size) / np.array(img_orig_size)\n",
    "\n",
    "tmp_size = resized_img_size.copy()\n",
    "tmp_size.append(img.shape[3])\n",
    "img_resized = np.zeros(tmp_size, dtype=np.float32)\n",
    "\n",
    "for channel in range(img.shape[3]):\n",
    "    data_one_channel = img[..., channel]\n",
    "    data_one_channel = zoom(data_one_channel, factor, order=1)\n",
    "    data_one_channel = norm_percentile_nocrop(\n",
    "        data_one_channel, normalization_percentile\n",
    "    )\n",
    "    img_resized[..., channel] = data_one_channel\n",
    "\n",
    "img = img_resized\n",
    "img = img.astype(np.float32)\n",
    "img = np.transpose(img, (3, 0, 1, 2)).copy()\n",
    "img = torch.from_numpy(img)\n",
    "\n",
    "print(img.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576fc129",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6beae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.to(device)\n",
    "\n",
    "res = predict_by_parts(model, img, crop_size=crop_size)\n",
    "\n",
    "img = img.detach().cpu().numpy()\n",
    "res = res.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ed87a",
   "metadata": {},
   "source": [
    "### Post Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_from_peaks(img, T, h, d, watershed_line=True, return_binary=False):\n",
    "    # 1) peak markers (enforces min_distance = d)\n",
    "    peak_idx = peak_local_max(\n",
    "        img,\n",
    "        min_distance=int(np.round(d)),\n",
    "        threshold_abs=T\n",
    "    )\n",
    "    maxima1 = np.zeros_like(img, dtype=bool)\n",
    "    if peak_idx.size:\n",
    "        maxima1[tuple(peak_idx.T)] = True\n",
    "\n",
    "    # 2) optional h-maxima filtering (like your current intersection)\n",
    "    maxima2 = h_maxima(img, h) if h is not None else np.ones_like(img, dtype=bool)\n",
    "\n",
    "    markers, _ = ndi_label(maxima1 & maxima2)  # labeled seeds: 1..N\n",
    "\n",
    "    # 3) foreground definition\n",
    "    mask = img >= T\n",
    "\n",
    "    # 4) 3D watershed segmentation\n",
    "    labels = watershed(-img, markers, mask=mask, watershed_line=watershed_line)\n",
    "\n",
    "    return (labels > 0) if return_binary else labels\n",
    "\n",
    "def detect(img, T, h, d):\n",
    "    p1 = peak_local_max(img, min_distance=int(np.round(d)), threshold_abs=T)\n",
    "    p2 = np.stack(np.nonzero(h_maxima(img, h)), axis=1)\n",
    "\n",
    "    p1 = set([tuple(x) for x in p1.tolist()])\n",
    "    p2 = set([tuple(x) for x in p2.tolist()])\n",
    "\n",
    "    detections = list(p1 | p2)\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee873f",
   "metadata": {},
   "source": [
    "### Slice GIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46ec9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-channel min-max normalization of res to [0, 1]\n",
    "res_norm = np.empty_like(res, dtype=np.float32)\n",
    "for c in range(res.shape[0]):\n",
    "    ch = res[c]\n",
    "    ch_min = ch.min()\n",
    "    ch_ptp = ch.ptp() + 1e-8\n",
    "    res_norm[c] = (ch - ch_min) / ch_ptp\n",
    "res = res_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "thresh = 0.1\n",
    "\n",
    "for channel in [0, 1]:\n",
    "    for slice_idx in (15, 20, 25):\n",
    "        img_select = img[channel, :, :, slice_idx]\n",
    "        prob = res[channel, :, :, slice_idx]\n",
    "\n",
    "        img_norm = (img_select - img_select.min()) / (img_select.ptp() + 1e-8)\n",
    "        base_img = np.zeros((*img_select.shape, 3), dtype=np.float32)\n",
    "        base_img[..., channel] = img_norm\n",
    "        base_img_uint8 = (base_img * 255).astype(np.uint8)\n",
    "\n",
    "        mask = prob > thresh\n",
    "        overlay = base_img_uint8.copy()\n",
    "        # magenta = red + blue\n",
    "        overlay[mask, 0] = 255\n",
    "        overlay[mask, 2] = 255\n",
    "\n",
    "        frames = [base_img_uint8, overlay]\n",
    "        gif_name = f\"model_prob_thresh_{'red' if channel == 0 else 'green'}_{slice_idx}.gif\"\n",
    "        imageio.mimsave(gif_name, frames, duration=1000, loop=0)\n",
    "        #display(Image(filename=gif_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio\n",
    "from IPython.display import Image, display\n",
    "\n",
    "points_channels = {}\n",
    "for channel in [0, 1]:\n",
    "    postprocessing_params = model.postprocessing_params[channel]\n",
    "    points = detect(\n",
    "        res[channel],\n",
    "        0.07, #postprocessing_params[\"T\"] * 0.9,\n",
    "        0.07, #postprocessing_params[\"h\"] * 0.9,\n",
    "        postprocessing_params[\"d\"] * 0.9,\n",
    "    )\n",
    "    points_channels[channel] = points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a299fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in [0, 1]:\n",
    "    for slice_idx in (15, 20, 25):\n",
    "        img_select = img[channel, :, :, slice_idx]\n",
    "\n",
    "        # Normalize to [0, 1] for display\n",
    "        img_norm = (img_select - img_select.min()) / (img_select.ptp() + 1e-8)\n",
    "\n",
    "        base_img = np.zeros((*img_select.shape, 3), dtype=np.float32)\n",
    "        base_img[..., channel] = img_norm\n",
    "\n",
    "        points = points_channels[channel]\n",
    "\n",
    "        # Overlay points in blue\n",
    "        rgb_overlay = base_img.copy()\n",
    "        for point in points:\n",
    "            if point[2] == slice_idx:  # Only mark points on this slice\n",
    "                y, x, z = point\n",
    "                if 0 <= y < rgb_overlay.shape[0] and 0 <= x < rgb_overlay.shape[1]:\n",
    "                    # Mark a small region around the point\n",
    "                    for dy in range(-2, 3):\n",
    "                        for dx in range(-2, 3):\n",
    "                            if 0 <= y+dy < rgb_overlay.shape[0] and 0 <= x+dx < rgb_overlay.shape[1]:\n",
    "                                rgb_overlay[y+dy, x+dx, 2] = 1  # Blue channel\n",
    "\n",
    "        # Convert to uint8 for GIF\n",
    "        base_img_uint8 = (base_img * 255).astype(np.uint8)\n",
    "        rgb_overlay_uint8 = (rgb_overlay * 255).astype(np.uint8)\n",
    "\n",
    "        # Save as GIF, 1 second per frame, loop forever\n",
    "        frames = [base_img_uint8, rgb_overlay_uint8]\n",
    "        gif_name = f\"model_predictions_{'red' if channel == 0 else 'green'}_{slice_idx}.gif\"\n",
    "        imageio.mimsave(gif_name, frames, duration=1000, loop=0)\n",
    "        #display(Image(filename=gif_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6f61d",
   "metadata": {},
   "source": [
    "### MSER-based colocalization segmentation (53BP1 + gH2AX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd0df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSER mask + seeded watershed on 53BP1*gH2AX colocalization\n",
    "def _normalize_uint8(volume):\n",
    "    vol = volume - volume.min()\n",
    "    denom = volume.ptp() + 1e-8\n",
    "    return (vol / denom * 255).astype(np.uint8)\n",
    "\n",
    "def mser_mask_volume(coloc_volume, delta=2, min_area=10, max_area=500, max_variation=0.25):\n",
    "    coloc_uint8 = _normalize_uint8(coloc_volume)\n",
    "    mser = cv2.MSER_create(\n",
    "        delta=delta,\n",
    "        min_area=min_area,\n",
    "        max_area=max_area,\n",
    "        max_variation=max_variation\n",
    "    )\n",
    "    mask = np.zeros_like(coloc_uint8, dtype=np.uint8)\n",
    "    for z in range(coloc_uint8.shape[2]):\n",
    "        slice_img = np.ascontiguousarray(coloc_uint8[:, :, z])\n",
    "        regions, _ = mser.detectRegions(slice_img)\n",
    "        if not regions:\n",
    "            continue\n",
    "        polys = [np.asarray(r, dtype=np.int32) for r in regions if len(r) >= 3]\n",
    "        if not polys:\n",
    "            continue\n",
    "        mask_slice = np.ascontiguousarray(mask[:, :, z])\n",
    "        cv2.fillPoly(mask_slice, polys, 255)\n",
    "        mask[:, :, z] = mask_slice\n",
    "    return mask.astype(bool)\n",
    "\n",
    "def seeds_from_points(points_dict, shape):\n",
    "    seeds = np.zeros(shape, dtype=np.int32)\n",
    "    seed_id = 1\n",
    "    for pts in points_dict.values():\n",
    "        for (y, x, z) in pts:\n",
    "            if 0 <= y < shape[0] and 0 <= x < shape[1] and 0 <= z < shape[2]:\n",
    "                if seeds[y, x, z] == 0:\n",
    "                    seeds[y, x, z] = seed_id\n",
    "                    seed_id += 1\n",
    "    return seeds\n",
    "\n",
    "coloc_img = img[0] * img[1]\n",
    "mser_mask = mser_mask_volume(\n",
    "    coloc_img,\n",
    "    delta=2,\n",
    "    min_area=10,\n",
    "    max_area=500,\n",
    "    max_variation=0.25\n",
    ")\n",
    "seed_labels = seeds_from_points(points_channels, coloc_img.shape)\n",
    "mser_watershed_labels = watershed(-coloc_img, markers=seed_labels, mask=mser_mask)\n",
    "\n",
    "print(f\"MSER mask voxels: {mser_mask.sum()} | Watershed instances: {mser_watershed_labels.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick visual check: raw channels, MSER mask, watershed labels, seeds\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "slices_to_show = [15, 20, 25]  # adjust as needed\n",
    "\n",
    "def _norm01(a):\n",
    "    a = a.astype(np.float32)\n",
    "    return (a - a.min()) / (a.ptp() + 1e-8)\n",
    "\n",
    "fig, axes = plt.subplots(len(slices_to_show), 4, figsize=(20, 4 * len(slices_to_show)))\n",
    "for row, z in enumerate(slices_to_show):\n",
    "    red = _norm01(img[0, :, :, z])\n",
    "    green = _norm01(img[1, :, :, z])\n",
    "    coloc = _norm01(coloc_img[:, :, z])\n",
    "    mask = mser_mask[:, :, z]\n",
    "    labels = mser_watershed_labels[:, :, z]\n",
    "    seeds = seed_labels[:, :, z]\n",
    "\n",
    "    # Base channels\n",
    "    axes[row, 0].imshow(np.stack([red, green, np.zeros_like(red)], axis=-1))\n",
    "    axes[row, 0].set_title(f\"53BP1+gH2AX z={z}\")\n",
    "\n",
    "    # Colocalization + MSER mask\n",
    "    axes[row, 1].imshow(coloc, cmap=\"magma\")\n",
    "    axes[row, 1].imshow(mask, cmap=\"Blues\", alpha=0.3)\n",
    "    axes[row, 1].set_title(\"Coloc + MSER mask\")\n",
    "\n",
    "    # Watershed labels overlay\n",
    "    axes[row, 2].imshow(coloc, cmap=\"gray\")\n",
    "    axes[row, 2].imshow(label2rgb(labels, bg_label=0, alpha=0.3))\n",
    "    axes[row, 2].set_title(\"Watershed labels\")\n",
    "\n",
    "    # Seeds\n",
    "    axes[row, 3].imshow(coloc, cmap=\"gray\")\n",
    "    ys, xs = np.nonzero(seeds)\n",
    "    axes[row, 3].scatter(xs, ys, s=10, c=\"cyan\", marker=\"o\", edgecolor=\"k\", linewidth=0.5)\n",
    "    axes[row, 3].set_title(\"Seeds (points)\")\n",
    "\n",
    "for ax_row in axes:\n",
    "    for ax in ax_row:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
